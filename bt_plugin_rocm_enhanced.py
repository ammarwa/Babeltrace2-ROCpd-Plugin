#!/usr/bin/env python3
"""
Enhanced Babeltrace2 plugin for reading ROCm profiler SQLite3 databases.

This plugin reads SQLite3 databases generated by rocprofv3 and converts
them into babeltrace2 trace events with category-based stream splitting
and channel-based organization.
"""
from typing import Dict, List, Optional, Any, Iterator, Set
from dataclasses import dataclass
import sqlite3
import os

# Import babeltrace2 library
import bt2

# Register the plugin
bt2.register_plugin(__name__, "rocm")

# ROCm profiler categories from rocprofiler-sdk (enhanced with full list)
ROCM_CATEGORIES = {
    'HSA_CORE_API': 'HSA Core API',
    'HSA_AMD_EXT_API': 'HSA AMD Extension API',
    'HSA_IMAGE_EXT_API': 'HSA Image Extension API',
    'HSA_FINALIZE_EXT_API': 'HSA Finalize Extension API',
    'HIP_RUNTIME_API': 'HIP Runtime API',
    'HIP_RUNTIME_API_EXT': 'HIP Runtime API Extended',
    'HIP_COMPILER_API': 'HIP Compiler API',
    'HIP_COMPILER_API_EXT': 'HIP Compiler API Extended',
    'MARKER_CORE_API': 'Marker Core API',
    'MARKER_CONTROL_API': 'Marker Control API',
    'MARKER_NAME_API': 'Marker Name API',
    'MEMORY_COPY': 'Memory Copy',
    'MEMORY_ALLOCATION': 'Memory Allocation',
    'KERNEL_DISPATCH': 'Kernel Dispatch',
    'SCRATCH_MEMORY': 'Scratch Memory',
    'CORRELATION_ID_RETIREMENT': 'Correlation ID Retirement',
    'RCCL_API': 'RCCL API',
    'OMPT': 'OpenMP Tools',
    'RUNTIME_INITIALIZATION': 'Runtime Initialization',
    'ROCDECODE_API': 'ROCDecode API',
    'ROCDECODE_API_EXT': 'ROCDecode API Extended',
    'ROCJPEG_API': 'ROCJPEG API',
    'HIP_STREAM': 'HIP Stream',
    'KFD_EVENT_PAGE_MIGRATE': 'KFD Event Page Migrate',
    'KFD_EVENT_PAGE_FAULT': 'KFD Event Page Fault',
    'KFD_EVENT_QUEUE': 'KFD Event Queue',
    'KFD_EVENT_UNMAP_FROM_GPU': 'KFD Event Unmap From GPU',
    'KFD_EVENT_DROPPED_EVENTS': 'KFD Event Dropped Events',
    'KFD_PAGE_MIGRATE': 'KFD Page Migrate',
    'KFD_PAGE_FAULT': 'KFD Page Fault',
    'KFD_QUEUE': 'KFD Queue'
}

@dataclass
class RocmEventData:
    """Data class for ROCm event information."""
    name: str
    timestamp: int
    duration: Optional[int] = None
    category: Optional[str] = None
    pid: Optional[int] = None
    tid: Optional[int] = None
    agent_id: Optional[int] = None
    queue_id: Optional[int] = None
    stream_id: Optional[int] = None
    channel_id: Optional[str] = None
    event_args: Optional[Dict[str, Any]] = None


class RocmSourceIterator(bt2._UserMessageIterator):
    """Iterator for the ROCm source component."""
    
    def __init__(self, config, output_port):
        """Initialize the iterator."""
        self._output_port_name = output_port.name
        self._db_path = output_port.user_data['db_path']
        self._trace_class = output_port.user_data['trace_class']
        self._stream_classes = output_port.user_data['stream_classes']
        self._event_classes = output_port.user_data['event_classes']
        self._clock_class = output_port.user_data['clock_class']
        self._category = output_port.user_data['category']
        
        # Create trace and stream instances
        self._trace = self._trace_class()
        
        # Create streams for each category and channel (thread/queue/stream)
        self._streams = {}
        self._channels = {}
        
        # Initialize database connection
        self._conn = sqlite3.connect(self._db_path)
        self._conn.row_factory = sqlite3.Row
        
        # State management
        self._state = "stream_beginning"
        self._current_events = []
        self._event_index = 0
        self._sent_stream_beginning = set()
        
        # Get database UUID and GUID for table names
        self._uuid, self._guid = self._get_db_metadata()
        
        # Load all events for this category
        self._load_events()
    
    def _get_db_metadata(self) -> tuple:
        """Get UUID and GUID from database metadata."""
        try:
            cursor = self._conn.cursor()
            # Try to get metadata from the metadata table
            cursor.execute("SELECT tag, value FROM rocpd_metadata")
            metadata = dict(cursor.fetchall())
            uuid = metadata.get('uuid', '0000b6ad_2bac_7bac_82e7_5f0563eafa7f')
            guid = metadata.get('guid', '0000b6ad_2bac_7bac_82e7_5f0563eafa7f')
            return uuid, guid
        except sqlite3.Error:
            # If metadata table doesn't exist, use the UUID from table names
            try:
                cursor = self._conn.cursor()
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'rocpd_%_%'")
                tables = cursor.fetchall()
                if tables:
                    # Extract UUID from table name (e.g., rocpd_region_0000b6ad_2bac_7bac_82e7_5f0563eafa7f)
                    table_name = tables[0][0]
                    uuid = table_name.split('_', 2)[-1]
                    return uuid, uuid
            except sqlite3.Error:
                pass
            # Default UUID for this database
            return '0000b6ad_2bac_7bac_82e7_5f0563eafa7f', '0000b6ad_2bac_7bac_82e7_5f0563eafa7f'
    
    def _table_exists(self, table_name: str) -> bool:
        """Check if a table exists in the database."""
        try:
            cursor = self._conn.cursor()
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
                (table_name,)
            )
            return cursor.fetchone() is not None
        except sqlite3.Error:
            return False
    
    def _get_channel_id(self, event_data: RocmEventData) -> str:
        """Get channel ID based on thread_id, queue_id, or stream_id."""
        if event_data.tid is not None:
            return f"thread_{event_data.tid}"
        elif event_data.queue_id is not None:
            return f"queue_{event_data.queue_id}"
        elif event_data.stream_id is not None:
            return f"stream_{event_data.stream_id}"
        else:
            return f"default_{event_data.pid or 0}"
    
    def _get_or_create_stream(self, event_data: RocmEventData):
        """Get or create a stream for the given event data."""
        channel_id = self._get_channel_id(event_data)
        stream_key = f"{self._category}_{channel_id}"
        
        if stream_key not in self._streams:
            # Get the appropriate stream class for this category
            stream_class = self._stream_classes.get(self._category, self._stream_classes['default'])
            
            # Create the stream
            stream = self._trace.create_stream(stream_class)
            self._streams[stream_key] = stream
            
            # Store channel info
            self._channels[stream_key] = {
                'category': self._category,
                'channel_id': channel_id,
                'tid': event_data.tid,
                'queue_id': event_data.queue_id,
                'stream_id': event_data.stream_id
            }
        
        return self._streams[stream_key]
    
    def _load_events(self):
        """Load all events from the database for this category."""
        self._current_events = []
        
        # Load different types of events based on category
        if self._category == 'all' or self._category in ['HIP_RUNTIME_API_EXT', 'HIP_COMPILER_API_EXT', 'HSA_CORE_API', 'HSA_AMD_EXT_API', 'MARKER_CORE_API']:
            if self._table_exists(f'rocpd_region_{self._uuid}'):
                self._load_region_events()
            elif self._table_exists(f'rocpd_region'):
                self._load_region_events()
                
        if self._category == 'all' or self._category == 'KERNEL_DISPATCH':
            if self._table_exists(f'rocpd_kernel_dispatch_{self._uuid}'):
                self._load_kernel_dispatch_events()
            elif self._table_exists(f'rocpd_kernel_dispatch'):
                self._load_kernel_dispatch_events()
                
        if self._category == 'all' or self._category == 'MEMORY_COPY':
            if self._table_exists(f'rocpd_memory_copy_{self._uuid}'):
                self._load_memory_copy_events()
            elif self._table_exists(f'rocpd_memory_copy'):
                self._load_memory_copy_events()
                
        if self._category == 'all' or self._category == 'MEMORY_ALLOCATION':
            if self._table_exists(f'rocpd_memory_allocate_{self._uuid}'):
                self._load_memory_allocation_events()
            elif self._table_exists(f'rocpd_memory_allocate'):
                self._load_memory_allocation_events()
        
        # Sort events by timestamp
        self._current_events.sort(key=lambda x: x.timestamp)
        
        print(f"Loaded {len(self._current_events)} events for category {self._category}")
    
    def _load_region_events(self):
        """Load region events from the database with category-based filtering."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            table_name = f'rocpd_region_{self._uuid}' if self._table_exists(f'rocpd_region_{self._uuid}') else 'rocpd_region'
            string_table_name = f'rocpd_string_{self._uuid}' if self._table_exists(f'rocpd_string_{self._uuid}') else 'rocpd_string'
            event_table_name = f'rocpd_event_{self._uuid}' if self._table_exists(f'rocpd_event_{self._uuid}') else 'rocpd_event'
            process_table_name = f'rocpd_info_process_{self._uuid}' if self._table_exists(f'rocpd_info_process_{self._uuid}') else 'rocpd_info_process'
            thread_table_name = f'rocpd_info_thread_{self._uuid}' if self._table_exists(f'rocpd_info_thread_{self._uuid}') else 'rocpd_info_thread'
            
            # Build category filter
            category_filter = ""
            if self._category != 'all':
                category_filter = f"AND s2.string = '{self._category}'"
            
            query = f"""
            SELECT 
                r.start, r.end, r.nid, r.pid, r.tid,
                s1.string as region_name,
                COALESCE(s2.string, 'unknown') as category,
                COALESCE(p.command, 'unknown') as process_name,
                COALESCE(t.name, 'unknown') as thread_name,
                r.extdata,
                e.correlation_id,
                e.call_stack,
                e.line_info
            FROM {table_name} r
            JOIN {string_table_name} s1 ON r.name_id = s1.id
            LEFT JOIN {event_table_name} e ON r.event_id = e.id
            LEFT JOIN {string_table_name} s2 ON e.category_id = s2.id
            LEFT JOIN {process_table_name} p ON r.pid = p.id
            LEFT JOIN {thread_table_name} t ON r.tid = t.id
            WHERE 1=1 {category_filter}
            ORDER BY r.start
            """
            cursor.execute(query)
            
            for row in cursor.fetchall():
                category = row['category'].lower() if row['category'] != 'unknown' else 'unknown'
                duration = row['end'] - row['start']
                
                # Create comprehensive event args
                common_args = {
                    'region_name': row['region_name'],
                    'category': row['category'],
                    'process_name': row['process_name'],
                    'thread_name': row['thread_name'],
                    'pid': row['pid'],
                    'tid': row['tid'],
                    'nid': row['nid'],
                    'correlation_id': row['correlation_id'] or 0,
                    'extdata': row['extdata'] or '{}',
                    'call_stack': row['call_stack'] or '{}',
                    'line_info': row['line_info'] or '{}'
                }
                
                # Region start event
                start_args = common_args.copy()
                start_args.update({
                    'event_type': 'region_start',
                    'duration': 0
                })
                
                self._current_events.append(RocmEventData(
                    name=f"{row['region_name']}_start",
                    timestamp=row['start'],
                    category=category,
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args=start_args
                ))
                
                # Region end event
                end_args = common_args.copy()
                end_args.update({
                    'event_type': 'region_end',
                    'duration': duration
                })
                
                self._current_events.append(RocmEventData(
                    name=f"{row['region_name']}_end",
                    timestamp=row['end'],
                    category=category,
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args=end_args
                ))
                
        except sqlite3.Error as e:
            print(f"Error loading region events: {e}")
    
    def _load_kernel_dispatch_events(self):
        """Load kernel dispatch events from the database."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            kd_table = f'rocpd_kernel_dispatch_{self._uuid}' if self._table_exists(f'rocpd_kernel_dispatch_{self._uuid}') else 'rocpd_kernel_dispatch'
            ks_table = f'rocpd_info_kernel_symbol_{self._uuid}' if self._table_exists(f'rocpd_info_kernel_symbol_{self._uuid}') else 'rocpd_info_kernel_symbol'
            
            query = f"""
            SELECT 
                k.start, k.end, k.nid, k.pid, k.tid, k.agent_id,
                k.dispatch_id, k.queue_id, k.stream_id,
                k.workgroup_size_x, k.workgroup_size_y, k.workgroup_size_z,
                k.grid_size_x, k.grid_size_y, k.grid_size_z,
                ks.kernel_name, ks.display_name,
                'kernel_dispatch' as category
            FROM {kd_table} k
            JOIN {ks_table} ks ON k.kernel_id = ks.id
            ORDER BY k.start
            """
            cursor.execute(query)
            
            for row in cursor.fetchall():
                kernel_name = row['kernel_name'] or row['display_name'] or 'unknown_kernel'
                
                # Kernel dispatch start event
                self._current_events.append(RocmEventData(
                    name=f"kernel_dispatch_start",
                    timestamp=row['start'],
                    category='kernel_dispatch',
                    pid=row['pid'],
                    tid=row['tid'],
                    agent_id=row['agent_id'],
                    queue_id=row['queue_id'],
                    stream_id=row['stream_id'],
                    event_args={
                        'kernel_name': kernel_name,
                        'dispatch_id': row['dispatch_id'],
                        'queue_id': row['queue_id'],
                        'stream_id': row['stream_id'],
                        'workgroup_size': f"{row['workgroup_size_x']}x{row['workgroup_size_y']}x{row['workgroup_size_z']}",
                        'grid_size': f"{row['grid_size_x']}x{row['grid_size_y']}x{row['grid_size_z']}",
                        'event_type': 'kernel_dispatch_start'
                    }
                ))
                
                # Kernel dispatch end event
                self._current_events.append(RocmEventData(
                    name=f"kernel_dispatch_end",
                    timestamp=row['end'],
                    category='kernel_dispatch',
                    pid=row['pid'],
                    tid=row['tid'],
                    agent_id=row['agent_id'],
                    queue_id=row['queue_id'],
                    stream_id=row['stream_id'],
                    event_args={
                        'kernel_name': kernel_name,
                        'dispatch_id': row['dispatch_id'],
                        'event_type': 'kernel_dispatch_end',
                        'duration': row['end'] - row['start']
                    }
                ))
                
        except sqlite3.Error as e:
            print(f"Error loading kernel dispatch events: {e}")
    
    def _load_memory_copy_events(self):
        """Load memory copy events from the database."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            mc_table = f'rocpd_memory_copy_{self._uuid}' if self._table_exists(f'rocpd_memory_copy_{self._uuid}') else 'rocpd_memory_copy'
            string_table = f'rocpd_string_{self._uuid}' if self._table_exists(f'rocpd_string_{self._uuid}') else 'rocpd_string'
            
            query = f"""
            SELECT 
                m.start, m.end, m.nid, m.pid, m.tid,
                m.size, m.dst_agent_id, m.src_agent_id,
                m.queue_id, m.stream_id,
                s.string as name,
                'memory_copy' as category
            FROM {mc_table} m
            JOIN {string_table} s ON m.name_id = s.id
            ORDER BY m.start
            """
            cursor.execute(query)
            
            for row in cursor.fetchall():
                # Memory copy start event
                self._current_events.append(RocmEventData(
                    name=f"memory_copy_start",
                    timestamp=row['start'],
                    category='memory_copy',
                    pid=row['pid'],
                    tid=row['tid'],
                    queue_id=row['queue_id'],
                    stream_id=row['stream_id'],
                    event_args={
                        'copy_name': row['name'],
                        'size': row['size'],
                        'dst_agent_id': row['dst_agent_id'],
                        'src_agent_id': row['src_agent_id'],
                        'queue_id': row['queue_id'],
                        'stream_id': row['stream_id'],
                        'event_type': 'memory_copy_start'
                    }
                ))
                
                # Memory copy end event
                self._current_events.append(RocmEventData(
                    name=f"memory_copy_end",
                    timestamp=row['end'],
                    category='memory_copy',
                    pid=row['pid'],
                    tid=row['tid'],
                    queue_id=row['queue_id'],
                    stream_id=row['stream_id'],
                    event_args={
                        'copy_name': row['name'],
                        'size': row['size'],
                        'event_type': 'memory_copy_end',
                        'duration': row['end'] - row['start']
                    }
                ))
                
        except sqlite3.Error as e:
            print(f"Error loading memory copy events: {e}")
    
    def _load_memory_allocation_events(self):
        """Load memory allocation events from the database."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            ma_table = f'rocpd_memory_allocate_{self._uuid}' if self._table_exists(f'rocpd_memory_allocate_{self._uuid}') else 'rocpd_memory_allocate'
            string_table = f'rocpd_string_{self._uuid}' if self._table_exists(f'rocpd_string_{self._uuid}') else 'rocpd_string'
            
            # Check if name_id column exists in the memory allocation table
            cursor.execute(f"PRAGMA table_info({ma_table})")
            columns = [col[1] for col in cursor.fetchall()]
            has_name_id = 'name_id' in columns
            
            if has_name_id:
                query = f"""
                SELECT 
                    m.start, m.end, m.nid, m.pid, m.tid,
                    m.size, m.agent_id, m.address as ptr,
                    s.string as name,
                    'memory_allocation' as category
                FROM {ma_table} m
                JOIN {string_table} s ON m.name_id = s.id
                ORDER BY m.start
                """
            else:
                query = f"""
                SELECT 
                    m.start, m.end, m.nid, m.pid, m.tid,
                    m.size, m.agent_id, m.address as ptr,
                    'memory_allocation' as name,
                    'memory_allocation' as category
                FROM {ma_table} m
                ORDER BY m.start
                """
            cursor.execute(query)
            
            for row in cursor.fetchall():
                # Memory allocation start event
                self._current_events.append(RocmEventData(
                    name=f"memory_allocation_start",
                    timestamp=row['start'],
                    category='memory_allocation',
                    pid=row['pid'],
                    tid=row['tid'],
                    agent_id=row['agent_id'],
                    event_args={
                        'allocation_name': row['name'],
                        'size': row['size'],
                        'ptr': row['ptr'],
                        'agent_id': row['agent_id'],
                        'event_type': 'memory_allocation_start'
                    }
                ))
                
                # Memory allocation end event
                self._current_events.append(RocmEventData(
                    name=f"memory_allocation_end",
                    timestamp=row['end'],
                    category='memory_allocation',
                    pid=row['pid'],
                    tid=row['tid'],
                    agent_id=row['agent_id'],
                    event_args={
                        'allocation_name': row['name'],
                        'size': row['size'],
                        'event_type': 'memory_allocation_end',
                        'duration': row['end'] - row['start']
                    }
                ))
                
        except sqlite3.Error as e:
            print(f"Error loading memory allocation events: {e}")
    
    def __next__(self):
        """Return the next message."""
        if self._state == "stream_beginning":
            self._state = "events"
            # Send stream beginning messages for all streams used by this category
            if self._current_events:
                # Get first event to determine which stream to begin
                first_event = self._current_events[0]
                stream = self._get_or_create_stream(first_event)
                return self._create_stream_beginning_message(stream)
            else:
                self._state = "done"
                raise StopIteration
        
        elif self._state == "events":
            if self._event_index < len(self._current_events):
                event_data = self._current_events[self._event_index]
                self._event_index += 1
                
                # Get or create stream for this event
                stream = self._get_or_create_stream(event_data)
                
                # Check if we need to send stream beginning for this stream
                stream_key = f"{self._category}_{self._get_channel_id(event_data)}"
                if stream_key not in self._sent_stream_beginning:
                    self._sent_stream_beginning.add(stream_key)
                    # We already sent the first stream beginning, so continue with event
                
                # Determine event class based on event category and name
                event_class_name = self._get_event_class_name_by_category(event_data)
                event_class = self._event_classes.get(event_class_name)
                
                if event_class is None:
                    # Fall back to generic event if specific class not found
                    event_class_name = "generic_event"
                    event_class = self._event_classes.get(event_class_name)
                
                if event_class is None:
                    # Skip unknown event types
                    return self.__next__()
                
                # Create event message
                msg = self._create_event_message(
                    event_class,
                    stream,
                    default_clock_snapshot=event_data.timestamp
                )
                
                # Set event fields
                if event_data.event_args:
                    for key, value in event_data.event_args.items():
                        if key in msg.event.payload_field:
                            msg.event.payload_field[key] = value
                
                return msg
            else:
                self._state = "stream_end"
                return self.__next__()
        
        elif self._state == "stream_end":
            # Send stream end messages for all streams
            if self._streams:
                stream_key = list(self._streams.keys())[0]
                stream = self._streams[stream_key]
                del self._streams[stream_key]
                return self._create_stream_end_message(stream)
            else:
                self._state = "done"
                raise StopIteration
        
        else:
            raise StopIteration
    
    def _get_event_class_name_by_category(self, event_data: RocmEventData) -> str:
        """Get the event class name based on event category and name."""
        if hasattr(event_data, 'category') and event_data.category:
            category = event_data.category.lower()
            
            # Map categories to specific event types
            if category == 'hip_runtime_api_ext':
                return 'hip_runtime_region_event'
            elif category == 'hip_compiler_api_ext':
                return 'hip_compiler_region_event'
            elif category == 'kernel_dispatch':
                return 'kernel_dispatch_event'
            elif category == 'memory_copy':
                return 'memory_copy_event'
            elif category == 'memory_allocation':
                return 'memory_allocation_event'
            elif "region" in event_data.name:
                return 'region_event'
        
        # Fall back to generic event
        return 'generic_event'
    
    def __del__(self):
        """Cleanup database connection."""
        if hasattr(self, '_conn'):
            self._conn.close()


@bt2.plugin_component_class
class RocmSource(bt2._UserSourceComponent, message_iterator_class=RocmSourceIterator):
    """Source component for reading ROCm profiler SQLite3 databases with category-based stream splitting."""
    
    @classmethod
    def _user_get_supported_mip_versions(cls, params, obj, log_level):
        """Declare supported MIP versions."""
        return [0]  # Support MIP version 0
    
    def __init__(self, config, params, obj):
        """Initialize the source component."""
        # Get database path from parameters
        self._db_path = str(params.get('db-path', '24228_results.db'))
        
        if not self._db_path:
            raise ValueError("Database path parameter 'db-path' is required")
        
        if not os.path.exists(self._db_path):
            raise FileNotFoundError(f"Database file not found: {self._db_path}")
        
        # Create trace class
        self._trace_class = super()._create_trace_class()
        
        # Create clock class
        self._clock_class = self._create_clock_class(
            name="rocm_clock",
            description="ROCm profiler clock",
            frequency=1_000_000_000  # Nanoseconds
        )
        
        # Get available categories from database
        self._categories = self._get_categories_from_db()
        
        # Create stream classes for each category
        self._stream_classes = self._create_stream_classes()
        
        # Create event classes
        self._event_classes = self._create_event_classes()
        
        # Create output ports for each category
        self._create_output_ports()
    
    def _get_categories_from_db(self) -> List[str]:
        """Get available categories from the database."""
        categories = []
        try:
            conn = sqlite3.connect(self._db_path)
            cursor = conn.cursor()
            
            # Get categories from events
            cursor.execute("""
                SELECT DISTINCT s.string as category 
                FROM rocpd_event e 
                JOIN rocpd_string s ON e.category_id = s.id 
                ORDER BY category
            """)
            
            for row in cursor.fetchall():
                categories.append(row[0])
            
            conn.close()
        except sqlite3.Error as e:
            print(f"Error getting categories from database: {e}")
            # Fall back to common categories
            categories = ['HIP_RUNTIME_API_EXT', 'HIP_COMPILER_API_EXT', 'KERNEL_DISPATCH', 'MEMORY_COPY', 'MEMORY_ALLOCATION']
        
        return categories
    
    def _create_stream_classes(self) -> Dict[str, Any]:
        """Create stream classes for different categories."""
        stream_classes = {}
        
        # Create a stream class for each category
        for category in self._categories:
            stream_class = self._trace_class.create_stream_class(
                name=f"rocm_{category.lower()}_stream",
                default_clock_class=self._clock_class
            )
            stream_classes[category] = stream_class
        
        # Create a default stream class
        default_stream_class = self._trace_class.create_stream_class(
            name="rocm_default_stream",
            default_clock_class=self._clock_class
        )
        stream_classes['default'] = default_stream_class
        
        return stream_classes
    
    def _create_output_ports(self):
        """Create output ports for each category."""
        for category in self._categories:
            self._add_output_port(f"out_{category.lower()}", {
                'db_path': self._db_path,
                'trace_class': self._trace_class,
                'stream_classes': self._stream_classes,
                'event_classes': self._event_classes,
                'clock_class': self._clock_class,
                'category': category
            })
        
        # Add a port for all categories combined
        self._add_output_port("out_all", {
            'db_path': self._db_path,
            'trace_class': self._trace_class,
            'stream_classes': self._stream_classes,
            'event_classes': self._event_classes,
            'clock_class': self._clock_class,
            'category': 'all'
        })
    
    def _create_clock_class(self, name: str, description: str, frequency: int):
        """Create a clock class for ROCm events."""
        clock_class = super()._create_clock_class(
            name=name,
            description=description,
            frequency=frequency
        )
        return clock_class

    def _create_event_classes(self) -> Dict[str, Any]:
        """Create event classes for different ROCm event types."""
        event_classes = {}
        
        # Create a comprehensive field class for region events
        def create_region_field_class():
            fc = self._trace_class.create_structure_field_class()
            fc.append_member("region_name", self._trace_class.create_string_field_class())
            fc.append_member("event_type", self._trace_class.create_string_field_class())
            fc.append_member("category", self._trace_class.create_string_field_class())
            fc.append_member("process_name", self._trace_class.create_string_field_class())
            fc.append_member("thread_name", self._trace_class.create_string_field_class())
            fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("extdata", self._trace_class.create_string_field_class())
            fc.append_member("call_stack", self._trace_class.create_string_field_class())
            fc.append_member("line_info", self._trace_class.create_string_field_class())
            return fc
        
        # Region event class
        region_event_class = self._stream_classes['default'].create_event_class(
            name="region_event",
            payload_field_class=create_region_field_class()
        )
        event_classes["region_event"] = region_event_class
        
        # HIP Runtime API region events
        hip_runtime_region_event_class = self._stream_classes['default'].create_event_class(
            name="hip_runtime_region_event",
            payload_field_class=create_region_field_class()
        )
        event_classes["hip_runtime_region_event"] = hip_runtime_region_event_class
        
        # HIP Compiler API region events
        hip_compiler_region_event_class = self._stream_classes['default'].create_event_class(
            name="hip_compiler_region_event",
            payload_field_class=create_region_field_class()
        )
        event_classes["hip_compiler_region_event"] = hip_compiler_region_event_class
        
        # Kernel dispatch event class
        kernel_payload_fc = self._trace_class.create_structure_field_class()
        kernel_payload_fc.append_member("kernel_name", self._trace_class.create_string_field_class())
        kernel_payload_fc.append_member("event_type", self._trace_class.create_string_field_class())
        kernel_payload_fc.append_member("dispatch_id", self._trace_class.create_signed_integer_field_class(64))
        kernel_payload_fc.append_member("queue_id", self._trace_class.create_signed_integer_field_class(64))
        kernel_payload_fc.append_member("stream_id", self._trace_class.create_signed_integer_field_class(64))
        kernel_payload_fc.append_member("workgroup_size", self._trace_class.create_string_field_class())
        kernel_payload_fc.append_member("grid_size", self._trace_class.create_string_field_class())
        kernel_payload_fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
        kernel_event_class = self._stream_classes['default'].create_event_class(
            name="kernel_dispatch_event",
            payload_field_class=kernel_payload_fc
        )
        event_classes["kernel_dispatch_event"] = kernel_event_class
        
        # Memory copy event class
        memory_payload_fc = self._trace_class.create_structure_field_class()
        memory_payload_fc.append_member("copy_name", self._trace_class.create_string_field_class())
        memory_payload_fc.append_member("event_type", self._trace_class.create_string_field_class())
        memory_payload_fc.append_member("size", self._trace_class.create_signed_integer_field_class(64))
        memory_payload_fc.append_member("dst_agent_id", self._trace_class.create_signed_integer_field_class(64))
        memory_payload_fc.append_member("src_agent_id", self._trace_class.create_signed_integer_field_class(64))
        memory_payload_fc.append_member("queue_id", self._trace_class.create_signed_integer_field_class(64))
        memory_payload_fc.append_member("stream_id", self._trace_class.create_signed_integer_field_class(64))
        memory_payload_fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
        memory_event_class = self._stream_classes['default'].create_event_class(
            name="memory_copy_event",
            payload_field_class=memory_payload_fc
        )
        event_classes["memory_copy_event"] = memory_event_class
        
        # Memory allocation event class
        allocation_payload_fc = self._trace_class.create_structure_field_class()
        allocation_payload_fc.append_member("allocation_name", self._trace_class.create_string_field_class())
        allocation_payload_fc.append_member("event_type", self._trace_class.create_string_field_class())
        allocation_payload_fc.append_member("size", self._trace_class.create_signed_integer_field_class(64))
        allocation_payload_fc.append_member("ptr", self._trace_class.create_signed_integer_field_class(64))
        allocation_payload_fc.append_member("agent_id", self._trace_class.create_signed_integer_field_class(64))
        allocation_payload_fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
        allocation_event_class = self._stream_classes['default'].create_event_class(
            name="memory_allocation_event",
            payload_field_class=allocation_payload_fc
        )
        event_classes["memory_allocation_event"] = allocation_event_class
        
        # Generic event class
        generic_payload_fc = self._trace_class.create_structure_field_class()
        generic_payload_fc.append_member("event_type", self._trace_class.create_string_field_class())
        generic_event_class = self._stream_classes['default'].create_event_class(
            name="generic_event",
            payload_field_class=generic_payload_fc
        )
        event_classes["generic_event"] = generic_event_class
        
        return event_classes
    
    @staticmethod
    def _user_query(priv_executor, obj, query, params):
        """Handle query requests."""
        if query == "babeltrace.support-info":
            # Support SQLite3 files that contain ROCm profiler tables
            input_value = params.get('input')
            if not input_value:
                return {'weight': 0.0}
            
            # Check if it's a file path
            if not isinstance(input_value, str):
                return {'weight': 0.0}
            
            # Check if file exists and is SQLite
            if not os.path.exists(input_value):
                return {'weight': 0.0}
            
            try:
                # Quick check if it's a SQLite database with ROCm tables
                conn = sqlite3.connect(input_value)
                cursor = conn.cursor()
                
                # Check for ROCm-specific tables
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'rocpd_%'")
                rocm_tables = cursor.fetchall()
                
                conn.close()
                
                if rocm_tables:
                    return {'weight': 1.0}  # Perfect match
                else:
                    return {'weight': 0.0}  # Not a ROCm database
                    
            except Exception:
                return {'weight': 0.0}
        
        elif query == "babeltrace.mip-version":
            # Declare MIP version support
            return 0  # Support MIP version 0
        
        return None
