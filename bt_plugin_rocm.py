#!/usr/bin/env python3
"""
Babeltrace2 plugin for reading ROCm profiler SQLite3 databases.

This plugin reads SQLite3 databases generated by rocprofv3 and converts
them into babeltrace2 trace events with category-based stream splitting
and channel-based organization.
"""

import bt2
import sqlite3
import os
import json
from typing import Dict, List, Optional, Any, Iterator, Set
from dataclasses import dataclass
from enum import Enum, auto
import re

# Import babeltrace2 library
import bt2

# Register the plugin
bt2.register_plugin(__name__, "rocm")


class RocmCategory(Enum):
    """ROCm profiler categories from rocprofiler-sdk."""
    HSA_CORE_API = 'HSA_CORE_API'
    HSA_AMD_EXT_API = 'HSA_AMD_EXT_API'
    HSA_IMAGE_EXT_API = 'HSA_IMAGE_EXT_API'
    HSA_FINALIZE_EXT_API = 'HSA_FINALIZE_EXT_API'
    HIP_RUNTIME_API = 'HIP_RUNTIME_API'
    HIP_RUNTIME_API_EXT = 'HIP_RUNTIME_API_EXT'
    HIP_COMPILER_API = 'HIP_COMPILER_API'
    HIP_COMPILER_API_EXT = 'HIP_COMPILER_API_EXT'
    MARKER_CORE_API = 'MARKER_CORE_API'
    MARKER_CONTROL_API = 'MARKER_CONTROL_API'
    MARKER_NAME_API = 'MARKER_NAME_API'
    MEMORY_COPY = 'MEMORY_COPY'
    MEMORY_ALLOCATION = 'MEMORY_ALLOCATION'
    KERNEL_DISPATCH = 'KERNEL_DISPATCH'
    SCRATCH_MEMORY = 'SCRATCH_MEMORY'
    CORRELATION_ID_RETIREMENT = 'CORRELATION_ID_RETIREMENT'
    RCCL_API = 'RCCL_API'
    OMPT = 'OMPT'
    RUNTIME_INITIALIZATION = 'RUNTIME_INITIALIZATION'
    ROCDECODE_API = 'ROCDECODE_API'
    ROCDECODE_API_EXT = 'ROCDECODE_API_EXT'
    ROCJPEG_API = 'ROCJPEG_API'
    HIP_STREAM = 'HIP_STREAM'
    KFD_EVENT_PAGE_MIGRATE = 'KFD_EVENT_PAGE_MIGRATE'
    KFD_EVENT_PAGE_FAULT = 'KFD_EVENT_PAGE_FAULT'
    KFD_EVENT_QUEUE = 'KFD_EVENT_QUEUE'
    KFD_EVENT_UNMAP_FROM_GPU = 'KFD_EVENT_UNMAP_FROM_GPU'
    KFD_EVENT_DROPPED_EVENTS = 'KFD_EVENT_DROPPED_EVENTS'
    KFD_PAGE_MIGRATE = 'KFD_PAGE_MIGRATE'
    KFD_PAGE_FAULT = 'KFD_PAGE_FAULT'
    KFD_QUEUE = 'KFD_QUEUE'


class EventType(Enum):
    """Event type classifications."""
    REGION_START = 'region_start'
    REGION_END = 'region_end'
    KERNEL_DISPATCH_START = 'kernel_dispatch_start'
    KERNEL_DISPATCH_END = 'kernel_dispatch_end'
    MEMORY_COPY_START = 'memory_copy_start'
    MEMORY_COPY_END = 'memory_copy_end'
    MEMORY_ALLOCATION_START = 'memory_allocation_start'
    MEMORY_ALLOCATION_END = 'memory_allocation_end'
    SAMPLE = 'sample'
    COUNTER_COLLECTION = 'counter_collection'


class EventClassBaseName(Enum):
    """Base names for event classes."""
    HIP_RUNTIME_REGION_EVENT = 'hip_runtime_region_event'
    HIP_COMPILER_REGION_EVENT = 'hip_compiler_region_event'
    HSA_CORE_REGION_EVENT = 'hsa_core_region_event'
    HSA_AMD_EXT_REGION_EVENT = 'hsa_amd_ext_region_event'
    MARKER_CORE_REGION_EVENT = 'marker_core_region_event'
    KERNEL_DISPATCH_EVENT = 'kernel_dispatch_event'
    MEMORY_COPY_EVENT = 'memory_copy_event'
    MEMORY_ALLOCATION_EVENT = 'memory_allocation_event'
    COUNTER_COLLECTION_EVENT = 'counter_collection_event'
    ROCDECODE_REGION_EVENT = 'rocdecode_region_event'
    ROCJPEG_REGION_EVENT = 'rocjpeg_region_event'
    SCRATCH_MEMORY_REGION_EVENT = 'scratch_memory_region_event'
    RCCL_API_REGION_EVENT = 'rccl_api_region_event'
    OMPT_REGION_EVENT = 'ompt_region_event'
    KFD_PAGE_MIGRATE_REGION_EVENT = 'kfd_page_migrate_region_event'
    KFD_PAGE_FAULT_REGION_EVENT = 'kfd_page_fault_region_event'
    REGION_EVENT = 'region_event'
    SAMPLE_EVENT = 'sample_event'
    GENERIC_EVENT = 'generic_event'


class EventSuffix(Enum):
    """Event name suffixes."""
    START = '_start'
    END = '_end'


class TableName(Enum):
    """Database table names."""
    ROCPD_REGION = 'rocpd_region'
    ROCPD_STRING = 'rocpd_string'
    ROCPD_EVENT = 'rocpd_event'
    ROCPD_INFO_PROCESS = 'rocpd_info_process'
    ROCPD_INFO_THREAD = 'rocpd_info_thread'
    ROCPD_KERNEL_DISPATCH = 'rocpd_kernel_dispatch'
    ROCPD_INFO_KERNEL_SYMBOL = 'rocpd_info_kernel_symbol'
    ROCPD_MEMORY_COPY = 'rocpd_memory_copy'
    ROCPD_METADATA = 'rocpd_metadata'
    SAMPLES = 'samples'


class IteratorState(Enum):
    """Iterator state values."""
    STREAM_BEGINNING = 'stream_beginning'
    STREAM_END = 'stream_end'


class MetadataKey(Enum):
    """Metadata keys for database."""
    UUID = 'uuid'
    GUID = 'guid'
    DEFAULT = 'default'


# ROCm profiler categories with display names
ROCM_CATEGORIES = {
    RocmCategory.HSA_CORE_API.value: 'HSA Core API',
    RocmCategory.HSA_AMD_EXT_API.value: 'HSA AMD Extension API',
    RocmCategory.HSA_IMAGE_EXT_API.value: 'HSA Image Extension API',
    RocmCategory.HSA_FINALIZE_EXT_API.value: 'HSA Finalize Extension API',
    RocmCategory.HIP_RUNTIME_API.value: 'HIP Runtime API',
    RocmCategory.HIP_RUNTIME_API_EXT.value: 'HIP Runtime API Extended',
    RocmCategory.HIP_COMPILER_API.value: 'HIP Compiler API',
    RocmCategory.HIP_COMPILER_API_EXT.value: 'HIP Compiler API Extended',
    RocmCategory.MARKER_CORE_API.value: 'Marker Core API',
    RocmCategory.MARKER_CONTROL_API.value: 'Marker Control API',
    RocmCategory.MARKER_NAME_API.value: 'Marker Name API',
    RocmCategory.MEMORY_COPY.value: 'Memory Copy',
    RocmCategory.MEMORY_ALLOCATION.value: 'Memory Allocation',
    RocmCategory.KERNEL_DISPATCH.value: 'Kernel Dispatch',
    RocmCategory.SCRATCH_MEMORY.value: 'Scratch Memory',
    RocmCategory.CORRELATION_ID_RETIREMENT.value: 'Correlation ID Retirement',
    RocmCategory.RCCL_API.value: 'RCCL API',
    RocmCategory.OMPT.value: 'OpenMP Tools',
    RocmCategory.RUNTIME_INITIALIZATION.value: 'Runtime Initialization',
    RocmCategory.ROCDECODE_API.value: 'ROCDecode API',
    RocmCategory.ROCDECODE_API_EXT.value: 'ROCDecode API Extended',
    RocmCategory.ROCJPEG_API.value: 'ROCJPEG API',
    RocmCategory.HIP_STREAM.value: 'HIP Stream',
    RocmCategory.KFD_EVENT_PAGE_MIGRATE.value: 'KFD Event Page Migrate',
    RocmCategory.KFD_EVENT_PAGE_FAULT.value: 'KFD Event Page Fault',
    RocmCategory.KFD_EVENT_QUEUE.value: 'KFD Event Queue',
    RocmCategory.KFD_EVENT_UNMAP_FROM_GPU.value: 'KFD Event Unmap From GPU',
    RocmCategory.KFD_EVENT_DROPPED_EVENTS.value: 'KFD Event Dropped Events',
    RocmCategory.KFD_PAGE_MIGRATE.value: 'KFD Page Migrate',
    RocmCategory.KFD_PAGE_FAULT.value: 'KFD Page Fault',
    RocmCategory.KFD_QUEUE.value: 'KFD Queue'
}

@dataclass
class RocmEventData:
    """Data class for ROCm event information."""
    name: str
    timestamp: int
    duration: Optional[int] = None
    category: Optional[str] = None
    pid: Optional[int] = None
    tid: Optional[int] = None
    agent_id: Optional[int] = None
    queue_id: Optional[int] = None
    stream_id: Optional[int] = None
    channel_id: Optional[str] = None
    event_args: Optional[Dict[str, Any]] = None


class RocmSourceIterator(bt2._UserMessageIterator):
    """Iterator for the ROCm source component."""

    def __init__(self, config, output_port):
        """Initialize the iterator."""
        self._db_path = output_port.user_data['db_path']
        self._trace_class = output_port.user_data['trace_class']
        self._stream_class = output_port.user_data['stream_class']
        self._event_classes = output_port.user_data['event_classes']
        self._clock_class = output_port.user_data['clock_class']

        # Create trace and stream instances
        self._trace = self._trace_class()
        self._stream = self._trace.create_stream(self._stream_class)

        # Initialize database connection
        self._conn = sqlite3.connect(self._db_path)
        self._conn.row_factory = sqlite3.Row

        # State management
        self._state = IteratorState.STREAM_BEGINNING.value
        self._event_iterator = None
        self._current_events = []
        self._event_index = 0

        # Get database UUID and GUID for table names
        self._uuid, self._guid = self._get_db_metadata()

        # Load all events
        self._load_events()

    def _get_db_metadata(self) -> tuple:
        """Get UUID and GUID from database metadata."""
        try:
            cursor = self._conn.cursor()
            # Try to get metadata from the metadata table
            cursor.execute(f"SELECT tag, value FROM {TableName.ROCPD_METADATA.value}")
            metadata = dict(cursor.fetchall())
            uuid = metadata.get(MetadataKey.UUID.value, MetadataKey.DEFAULT.value)
            guid = metadata.get(MetadataKey.GUID.value, MetadataKey.DEFAULT.value)
            return uuid, guid
        except sqlite3.Error:
            # If metadata table doesn't exist, try to find UUID from table names
            try:
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'rocpd_%'")
                tables = cursor.fetchall()
                if tables:
                    # Extract UUID from table name (e.g., rocpd_region{uuid})
                    table_name = tables[0][0]
                    if '{' in table_name and '}' in table_name:
                        uuid = table_name.split('{')[1].split('}')[0]
                        return uuid, uuid
                    else:
                        # Try to find UUID pattern in table name
                        import re
                        uuid_pattern = r'rocpd_\w+([a-f0-9]{32})'
                        match = re.search(uuid_pattern, table_name)
                        if match:
                            uuid = match.group(1)
                            return uuid, uuid
            except sqlite3.Error:
                pass
            # If all else fails, use empty string (tables might not have UUID suffix)
            return '', ''

    def _table_exists(self, table_name: str) -> bool:
        """Check if a table or view exists in the database."""
        try:
            cursor = self._conn.cursor()
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE (type='table' OR type='view') AND name=?",
                (table_name,)
            )
            return cursor.fetchone() is not None
        except sqlite3.Error:
            return False

    def _load_events(self):
        """Load all events from the database using views."""
        self._current_events = []

        # Load different types of events from views, handling missing views gracefully
        if self._table_exists('regions'):
            self._load_region_events_from_view()
        else:
            print("Warning: View 'regions' not found")

        if self._table_exists('kernels'):
            self._load_kernel_events_from_view()
        else:
            print("Warning: View 'kernels' not found")

        if self._table_exists('memory_copies'):
            self._load_memory_copy_events_from_view()
        else:
            print("Warning: View 'memory_copies' not found")

        if self._table_exists('samples'):
            self._load_sample_events_from_view()
        else:
            print("Warning: View 'samples' not found")

        # Load memory allocation events
        if self._table_exists('memory_allocations'):
            self._load_memory_allocation_events_from_view()
        else:
            print("Warning: View 'memory_allocations' not found")

        # Load counter collection events
        if self._table_exists('counters_collection'):
            self._load_counter_collection_events()
        else:
            print("Warning: View 'counters_collection' not found")

        # Sort events by timestamp
        self._current_events.sort(key=lambda x: x.timestamp)

        print(f"Loaded {len(self._current_events)} events from database")

    def _load_region_events_from_view(self):
        """Load region events from the regions view with full information."""
        try:
            cursor = self._conn.cursor()

            query = """
            SELECT
                id, guid, category, name, nid, pid, tid, start, end, duration,
                event_id, stack_id, parent_stack_id, corr_id, extdata,
                call_stack, line_info
            FROM regions
            ORDER BY start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                category = row[2].lower() if row[2] else 'unknown'
                duration = row[9] if row[9] is not None else (row[8] - row[7] if row[8] and row[7] else 0)

                # Create comprehensive event args
                common_args = {
                    'region_id': row[0] or 0,
                    'guid': row[1] or '',
                    'name': row[3] or '',
                    'category': row[2] or '',
                    'nid': row[4] or 0,
                    'pid': row[5] or 0,
                    'tid': row[6] or 0,
                    'event_id': row[10] or 0,
                    'stack_id': row[11] or 0,
                    'parent_stack_id': row[12] or 0,
                    'correlation_id': row[13] or 0,
                    'extdata': str(row[14]) if row[14] else '{}',
                    'call_stack': str(row[15]) if row[15] else '{}',
                    'line_info': str(row[16]) if row[16] else '{}'
                }

                # Region start event
                start_args = common_args.copy()
                start_args.update({
                    'event_type': EventType.REGION_START.value,
                    'duration': 0
                })

                self._current_events.append(RocmEventData(
                    name=f"{row[3]}_start",
                    timestamp=row[7],
                    category=category,
                    pid=row[5],
                    tid=row[6],
                    event_args=start_args
                ))

                # Region end event
                end_args = common_args.copy()
                end_args.update({
                    'event_type': EventType.REGION_END.value,
                    'duration': duration
                })

                self._current_events.append(RocmEventData(
                    name=f"{row[3]}_end",
                    timestamp=row[8],
                    category=category,
                    pid=row[5],
                    tid=row[6],
                    event_args=end_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading region events from view: {e}")

    def _load_region_events(self):
        """Load region events from the database with category-based classification."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            table_name = f'{TableName.ROCPD_REGION.value}{self._uuid}' if self._uuid else TableName.ROCPD_REGION.value
            string_table_name = f'{TableName.ROCPD_STRING.value}{self._uuid}' if self._uuid else TableName.ROCPD_STRING.value
            event_table_name = f'{TableName.ROCPD_EVENT.value}{self._uuid}' if self._uuid else TableName.ROCPD_EVENT.value
            process_table_name = f'{TableName.ROCPD_INFO_PROCESS.value}{self._uuid}' if self._uuid else TableName.ROCPD_INFO_PROCESS.value
            thread_table_name = f'{TableName.ROCPD_INFO_THREAD.value}{self._uuid}' if self._uuid else TableName.ROCPD_INFO_THREAD.value

            query = f"""
            SELECT
                r.start, r.end, r.nid, r.pid, r.tid,
                s1.string as region_name,
                COALESCE(s2.string, 'unknown') as category,
                COALESCE(p.command, 'unknown') as process_name,
                COALESCE(t.name, 'unknown') as thread_name,
                r.extdata,
                e.correlation_id,
                e.call_stack,
                e.line_info
            FROM {table_name} r
            JOIN {string_table_name} s1 ON r.name_id = s1.id
            LEFT JOIN {event_table_name} e ON r.event_id = e.id
            LEFT JOIN {string_table_name} s2 ON e.category_id = s2.id
            LEFT JOIN {process_table_name} p ON r.pid = p.id
            LEFT JOIN {thread_table_name} t ON r.tid = t.id
            ORDER BY r.start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                category = row['category'].lower() if row['category'] != 'unknown' else 'unknown'
                duration = row['end'] - row['start']

                # Create comprehensive event args
                common_args = {
                    'region_name': row['region_name'],
                    'category': row['category'],
                    'process_name': row['process_name'],
                    'thread_name': row['thread_name'],
                    'pid': row['pid'],
                    'tid': row['tid'],
                    'nid': row['nid'],
                    'correlation_id': row['correlation_id'] or 0,
                    'extdata': row['extdata'] or '{}',
                    'call_stack': row['call_stack'] or '{}',
                    'line_info': row['line_info'] or '{}'
                }

                # Region start event
                start_args = common_args.copy()
                start_args.update({
                    'event_type': EventType.REGION_START.value,
                    'duration': 0
                })

                self._current_events.append(RocmEventData(
                    name=f"{row['region_name']}_start",
                    timestamp=row['start'],
                    category=category,
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args=start_args
                ))

                # Region end event
                end_args = common_args.copy()
                end_args.update({
                    'event_type': EventType.REGION_END.value,
                    'duration': duration
                })

                self._current_events.append(RocmEventData(
                    name=f"{row['region_name']}_end",
                    timestamp=row['end'],
                    category=category,
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args=end_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading region events: {e}")

    def _load_kernel_events_from_view(self):
        """Load kernel events from the kernels view with full information."""
        try:
            cursor = self._conn.cursor()

            query = """
            SELECT
                id, guid, tid, category, region, name, nid, pid,
                agent_abs_index, agent_log_index, agent_type_index, agent_type,
                code_object_id, kernel_id, dispatch_id, stream_id, queue_id,
                queue, stream, start, end, duration,
                grid_x, grid_y, grid_z, workgroup_x, workgroup_y, workgroup_z,
                lds_size, scratch_size, static_lds_size, static_scratch_size,
                stack_id, parent_stack_id, corr_id
            FROM kernels
            ORDER BY start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                kernel_name = row[5] or 'unknown_kernel'

                # Create comprehensive kernel args
                kernel_args = {
                    'kernel_id': row[0] or 0,
                    'guid': row[1] or '',
                    'tid': row[2] or 0,
                    'category': row[3] or '',
                    'region': row[4] or '',
                    'name': kernel_name,
                    'nid': row[6] or 0,
                    'pid': row[7] or 0,
                    'agent_abs_index': row[8] or 0,
                    'agent_log_index': row[9] or 0,
                    'agent_type_index': row[10] or 0,
                    'agent_type': row[11] or '',
                    'code_object_id': row[12] or 0,
                    'kernel_symbol_id': row[13] or 0,
                    'dispatch_id': row[14] or 0,
                    'stream_id': row[15] or 0,
                    'queue_id': row[16] or 0,
                    'queue_name': row[17] or '',
                    'stream_name': row[18] or '',
                    'grid_size_x': row[22] or 0,
                    'grid_size_y': row[23] or 0,
                    'grid_size_z': row[24] or 0,
                    'workgroup_size_x': row[25] or 0,
                    'workgroup_size_y': row[26] or 0,
                    'workgroup_size_z': row[27] or 0,
                    'lds_size': row[28] or 0,
                    'scratch_size': row[29] or 0,
                    'static_lds_size': row[30] or 0,
                    'static_scratch_size': row[31] or 0,
                    'stack_id': row[32] or 0,
                    'parent_stack_id': row[33] or 0,
                    'correlation_id': row[34] or 0,
                    'duration': row[21] if row[21] is not None else (row[20] - row[19] if row[20] and row[19] else 0)
                }

                # Kernel dispatch start event
                start_args = kernel_args.copy()
                start_args.update({
                    'event_type': EventType.KERNEL_DISPATCH_START.value,
                    'duration': 0
                })

                self._current_events.append(RocmEventData(
                    name=f"kernel_dispatch_start",
                    timestamp=row[19],
                    category='kernel_dispatch',
                    pid=row[7],
                    tid=row[2],
                    agent_id=row[8],  # Using agent_abs_index as agent_id
                    queue_id=row[16],
                    event_args=start_args
                ))

                # Kernel dispatch end event
                end_args = kernel_args.copy()
                end_args.update({
                    'event_type': EventType.KERNEL_DISPATCH_END.value
                })

                self._current_events.append(RocmEventData(
                    name=f"kernel_dispatch_end",
                    timestamp=row[20],
                    category='kernel_dispatch',
                    pid=row[7],
                    tid=row[2],
                    agent_id=row[8],  # Using agent_abs_index as agent_id
                    queue_id=row[16],
                    event_args=end_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading kernel events from view: {e}")

    def _load_kernel_dispatch_events(self):
        """Load kernel dispatch events from the database."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            kd_table = f'rocpd_kernel_dispatch{self._uuid}' if self._uuid else 'rocpd_kernel_dispatch'
            ks_table = f'rocpd_info_kernel_symbol{self._uuid}' if self._uuid else 'rocpd_info_kernel_symbol'

            query = f"""
            SELECT
                k.start, k.end, k.nid, k.pid, k.tid, k.agent_id,
                k.dispatch_id, k.queue_id, k.stream_id,
                k.workgroup_size_x, k.workgroup_size_y, k.workgroup_size_z,
                k.grid_size_x, k.grid_size_y, k.grid_size_z,
                ks.kernel_name, ks.display_name,
                'kernel_dispatch' as category
            FROM {kd_table} k
            JOIN {ks_table} ks ON k.kernel_id = ks.id
            ORDER BY k.start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                kernel_name = row['kernel_name'] or row['display_name'] or 'unknown_kernel'

                # Kernel dispatch start event
                self._current_events.append(RocmEventData(
                    name=f"kernel_dispatch_start",
                    timestamp=row['start'],
                    category=row['category'],
                    pid=row['pid'],
                    tid=row['tid'],
                    agent_id=row['agent_id'],
                    event_args={
                        'kernel_name': kernel_name,
                        'dispatch_id': row['dispatch_id'],
                        'queue_id': row['queue_id'],
                        'stream_id': row['stream_id'],
                        'workgroup_size': f"{row['workgroup_size_x']}x{row['workgroup_size_y']}x{row['workgroup_size_z']}",
                        'grid_size': f"{row['grid_size_x']}x{row['grid_size_y']}x{row['grid_size_z']}",
                        'event_type': EventType.KERNEL_DISPATCH_START.value
                    }
                ))

                # Kernel dispatch end event
                self._current_events.append(RocmEventData(
                    name=f"kernel_dispatch_end",
                    timestamp=row['end'],
                    category=row['category'],
                    pid=row['pid'],
                    tid=row['tid'],
                    agent_id=row['agent_id'],
                    event_args={
                        'kernel_name': kernel_name,
                        'dispatch_id': row['dispatch_id'],
                        'event_type': EventType.KERNEL_DISPATCH_END.value,
                        'duration': row['end'] - row['start']
                    }
                ))

        except sqlite3.Error as e:
            print(f"Error loading kernel dispatch events: {e}")

    def _load_memory_copy_events_from_view(self):
        """Load memory copy events from the memory_copies view with full information."""
        try:
            cursor = self._conn.cursor()

            query = """
            SELECT
                id, guid, category, nid, pid, tid, start, end, duration,
                name, region_name, stream_id, queue_id, stream_name, queue_name,
                size, dst_device, dst_agent_abs_index, dst_agent_log_index,
                dst_agent_type_index, dst_agent_type, dst_address,
                src_device, src_agent_abs_index, src_agent_log_index,
                src_agent_type_index, src_agent_type, src_address,
                stack_id, parent_stack_id, corr_id
            FROM memory_copies
            ORDER BY start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                copy_name = row[9] or 'unknown_copy'

                # Create comprehensive memory copy args
                memory_args = {
                    'copy_id': row[0] or 0,
                    'guid': row[1] or '',
                    'category': row[2] or '',
                    'nid': row[3] or 0,
                    'pid': row[4] or 0,
                    'tid': row[5] or 0,
                    'copy_name': copy_name,
                    'region_name': row[10] or '',
                    'stream_id': row[11] or 0,
                    'queue_id': row[12] or 0,
                    'stream_name': row[13] or '',
                    'queue_name': row[14] or '',
                    'size': row[15] or 0,
                    'dst_device': row[16] or '',
                    'dst_agent_abs_index': row[17] or 0,
                    'dst_agent_log_index': row[18] or 0,
                    'dst_agent_type_index': row[19] or 0,
                    'dst_agent_type': row[20] or '',
                    'dst_address': row[21] or 0,
                    'src_device': row[22] or '',
                    'src_agent_abs_index': row[23] or 0,
                    'src_agent_log_index': row[24] or 0,
                    'src_agent_type_index': row[25] or 0,
                    'src_agent_type': row[26] or '',
                    'src_address': row[27] or 0,
                    'stack_id': row[28] or 0,
                    'parent_stack_id': row[29] or 0,
                    'correlation_id': row[30] or 0,
                    'duration': row[8] if row[8] is not None else (row[7] - row[6] if row[7] and row[6] else 0)
                }

                # Memory copy start event
                start_args = memory_args.copy()
                start_args.update({
                    'event_type': EventType.MEMORY_COPY_START.value,
                    'duration': 0
                })

                self._current_events.append(RocmEventData(
                    name=f"memory_copy_start",
                    timestamp=row[6],
                    category='memory_copy',
                    pid=row[4],
                    tid=row[5],
                    queue_id=row[12],
                    stream_id=row[11],
                    event_args=start_args
                ))

                # Memory copy end event
                end_args = memory_args.copy()
                end_args.update({
                    'event_type': EventType.MEMORY_COPY_END.value
                })

                self._current_events.append(RocmEventData(
                    name=f"memory_copy_end",
                    timestamp=row[7],
                    category='memory_copy',
                    pid=row[4],
                    tid=row[5],
                    queue_id=row[12],
                    stream_id=row[11],
                    event_args=end_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading memory copy events from view: {e}")

    def _load_memory_copy_events(self):
        """Load memory copy events from the database."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            mc_table = f'rocpd_memory_copy{self._uuid}' if self._uuid else 'rocpd_memory_copy'
            string_table = f'rocpd_string{self._uuid}' if self._uuid else 'rocpd_string'

            # First check what columns are available in the memory copy table
            cursor.execute(f"PRAGMA table_info({mc_table})")
            columns = [row[1] for row in cursor.fetchall()]

            # Build query based on available columns
            if 'name_id' in columns:
                # If name_id exists, join with string table
                query = f"""
                SELECT
                    m.start, m.end, m.nid, m.pid, m.tid,
                    m.size, m.dst_agent_id, m.src_agent_id,
                    m.queue_id, m.stream_id,
                    COALESCE(s.string, 'MEMORY_COPY_UNKNOWN') as name,
                    'memory_copy' as category
                FROM {mc_table} m
                LEFT JOIN {string_table} s ON m.name_id = s.id
                ORDER BY m.start
                """
            else:
                # If name_id doesn't exist, use a default name
                query = f"""
                SELECT
                    m.start, m.end, m.nid, m.pid, m.tid,
                    m.size, m.dst_agent_id, m.src_agent_id,
                    m.queue_id, m.stream_id,
                    'MEMORY_COPY_DEVICE_TO_HOST' as name,
                    'memory_copy' as category
                FROM {mc_table} m
                ORDER BY m.start
                """

            cursor.execute(query)

            for row in cursor.fetchall():
                # Memory copy start event
                self._current_events.append(RocmEventData(
                    name=f"memory_copy_start",
                    timestamp=row['start'],
                    category=row['category'],
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args={
                        'copy_name': row['name'],
                        'size': row['size'],
                        'dst_agent_id': row['dst_agent_id'],
                        'src_agent_id': row['src_agent_id'],
                        'queue_id': row['queue_id'],
                        'stream_id': row['stream_id'],
                        'event_type': EventType.MEMORY_COPY_START.value
                    }
                ))

                # Memory copy end event
                self._current_events.append(RocmEventData(
                    name=f"memory_copy_end",
                    timestamp=row['end'],
                    category=row['category'],
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args={
                        'copy_name': row['name'],
                        'size': row['size'],
                        'event_type': EventType.MEMORY_COPY_END.value,
                        'duration': row['end'] - row['start']
                    }
                ))

        except sqlite3.Error as e:
            print(f"Error loading memory copy events: {e}")

    def _load_sample_events_from_view(self):
        """Load sample events from the samples view with full information."""
        try:
            cursor = self._conn.cursor()

            query = """
            SELECT
                id, guid, category, name, nid, pid, tid, timestamp,
                event_id, stack_id, parent_stack_id, corr_id,
                extdata, call_stack, line_info
            FROM samples
            ORDER BY timestamp
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                sample_name = row[3] or f"sample_{row[0]}"

                # Create comprehensive sample args
                sample_args = {
                    'sample_id': row[0] or 0,
                    'guid': row[1] or '',
                    'category': row[2] or '',
                    'sample_name': sample_name,
                    'nid': row[4] or 0,
                    'pid': row[5] or 0,
                    'tid': row[6] or 0,
                    'event_id': row[8] or 0,
                    'stack_id': row[9] or 0,
                    'parent_stack_id': row[10] or 0,
                    'correlation_id': row[11] or 0,
                    'extdata': str(row[12]) if row[12] else '{}',
                    'call_stack': str(row[13]) if row[13] else '{}',
                    'line_info': str(row[14]) if row[14] else '{}',
                    'event_type': EventType.SAMPLE.value
                }

                self._current_events.append(RocmEventData(
                    name=f"sample",
                    timestamp=row[7],
                    category='sample',
                    pid=row[5],
                    tid=row[6],
                    event_args=sample_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading sample events from view: {e}")

    def _load_sample_events(self):
        """Load sample events from the database."""
        try:
            cursor = self._conn.cursor()
            # Handle different table naming patterns
            sample_table = f'rocpd_sample{self._uuid}' if self._uuid else 'rocpd_sample'
            track_table = f'rocpd_track{self._uuid}' if self._uuid else 'rocpd_track'
            string_table = f'rocpd_string{self._uuid}' if self._uuid else 'rocpd_string'

            query = f"""
            SELECT
                s.timestamp, s.track_id,
                t.nid, t.pid, t.tid,
                str.string as track_name,
                'sample' as category
            FROM {sample_table} s
            JOIN {track_table} t ON s.track_id = t.id
            LEFT JOIN {string_table} str ON t.name_id = str.id
            ORDER BY s.timestamp
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                track_name = row['track_name'] or f"track_{row['track_id']}"

                self._current_events.append(RocmEventData(
                    name=f"sample",
                    timestamp=row['timestamp'],
                    category=row['category'],
                    pid=row['pid'],
                    tid=row['tid'],
                    event_args={
                        'track_name': track_name,
                        'track_id': row['track_id'],
                        'event_type': EventType.SAMPLE.value
                    }
                ))

        except sqlite3.Error as e:
            print(f"Error loading sample events: {e}")

    def _load_counter_collection_events(self):
        """Load counter collection events from the database."""
        try:
            cursor = self._conn.cursor()

            query = """
            SELECT
                id, guid, dispatch_id, kernel_id, event_id, correlation_id,
                stack_id, parent_stack_id, pid, tid, agent_id, agent_abs_index,
                agent_log_index, agent_type_index, agent_type, queue_id,
                grid_size_x, grid_size_y, grid_size_z, kernel_name, kernel_region,
                workgroup_size_x, workgroup_size_y, workgroup_size_z,
                lds_block_size, scratch_size, vgpr_count, accum_vgpr_count, sgpr_count,
                counter_name, counter_symbol, component, description, block, expression,
                value_type, counter_id, value, start, end, is_constant, is_derived,
                duration, category, nid, extdata, code_object_id
            FROM counters_collection
            ORDER BY start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                # Create counter collection event
                counter_args = {
                    'id': row[0] or 0,
                    'guid': row[1] or '',
                    'dispatch_id': row[2] or 0,
                    'kernel_id': row[3] or 0,
                    'event_id': row[4] or 0,
                    'correlation_id': row[5] or 0,
                    'stack_id': row[6] or 0,
                    'parent_stack_id': row[7] or 0,
                    'pid': row[8] or 0,
                    'tid': row[9] or 0,
                    'agent_id': row[10] or 0,
                    'agent_abs_index': row[11] or 0,
                    'agent_log_index': row[12] or 0,
                    'agent_type_index': row[13] or 0,
                    'agent_type': row[14] or '',
                    'queue_id': row[15] or 0,
                    'grid_size_x': row[16] or 0,
                    'grid_size_y': row[17] or 0,
                    'grid_size_z': row[18] or 0,
                    'kernel_name': row[19] or '',
                    'kernel_region': row[20] or '',
                    'workgroup_size_x': row[21] or 0,
                    'workgroup_size_y': row[22] or 0,
                    'workgroup_size_z': row[23] or 0,
                    'lds_block_size': row[24] or 0,
                    'scratch_size': row[25] or 0,
                    'vgpr_count': row[26] or 0,
                    'accum_vgpr_count': row[27] or 0,
                    'sgpr_count': row[28] or 0,
                    'counter_name': row[29] or '',
                    'counter_symbol': row[30] or '',
                    'component': row[31] or '',
                    'description': row[32] or '',
                    'block': row[33] or '',
                    'expression': row[34] or '',
                    'value_type': row[35] or '',
                    'counter_id': row[36] or 0,
                    'value': float(row[37]) if row[37] is not None else 0.0,
                    'start': row[38] or 0,
                    'end': row[39] or 0,
                    'is_constant': row[40] or 0,
                    'is_derived': row[41] or 0,
                    'duration': row[42] or 0,
                    'category': row[43] or '',
                    'nid': row[44] or 0,
                    'extdata': row[45] or '{}',
                    'code_object_id': row[46] or 0,
                    'event_type': EventType.COUNTER_COLLECTION.value
                }

                self._current_events.append(RocmEventData(
                    name="counter_collection",
                    timestamp=row[38] or 0,  # start timestamp
                    category='counter_collection',
                    pid=row[8] or 0,
                    tid=row[9] or 0,
                    agent_id=row[10] or 0,
                    queue_id=row[15] or 0,
                    event_args=counter_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading counter collection events: {e}")

    def _load_memory_allocation_events_from_view(self):
        """Load memory allocation events from the memory_allocations view."""
        try:
            cursor = self._conn.cursor()

            query = """
            SELECT
                id, guid, category, nid, pid, tid, start, end, duration,
                type, level, agent_name, agent_abs_index, agent_log_index,
                agent_type_index, agent_type, address, size, queue_id, queue_name,
                stream_id, stream_name, stack_id, parent_stack_id, corr_id
            FROM memory_allocations
            ORDER BY start
            """
            cursor.execute(query)

            for row in cursor.fetchall():
                # Create comprehensive memory allocation args
                alloc_args = {
                    'allocation_id': row[0] or 0,
                    'guid': row[1] or '',
                    'category': row[2] or '',
                    'nid': row[3] or 0,
                    'pid': row[4] or 0,
                    'tid': row[5] or 0,
                    'allocation_type': row[9] or '',
                    'level': row[10] or '',
                    'agent_name': row[11] or '',
                    'agent_abs_index': row[12] or 0,
                    'agent_log_index': row[13] or 0,
                    'agent_type_index': row[14] or 0,
                    'agent_type': row[15] or '',
                    'address': row[16] or 0,
                    'size': row[17] or 0,
                    'queue_id': row[18] or 0,
                    'queue_name': row[19] or '',
                    'stream_id': row[20] or 0,
                    'stream_name': row[21] or '',
                    'stack_id': row[22] or 0,
                    'parent_stack_id': row[23] or 0,
                    'correlation_id': row[24] or 0,
                    'duration': row[8] if row[8] is not None else (row[7] - row[6] if row[7] and row[6] else 0)
                }

                # Memory allocation start event
                start_args = alloc_args.copy()
                start_args.update({
                    'event_type': EventType.MEMORY_ALLOCATION_START.value,
                    'duration': 0
                })

                self._current_events.append(RocmEventData(
                    name="memory_allocation_start",
                    timestamp=row[6],
                    category='memory_allocation',
                    pid=row[4],
                    tid=row[5],
                    queue_id=row[18],
                    stream_id=row[20],
                    event_args=start_args
                ))

                # Memory allocation end event
                end_args = alloc_args.copy()
                end_args.update({
                    'event_type': EventType.MEMORY_ALLOCATION_END.value
                })

                self._current_events.append(RocmEventData(
                    name="memory_allocation_end",
                    timestamp=row[7],
                    category='memory_allocation',
                    pid=row[4],
                    tid=row[5],
                    queue_id=row[18],
                    stream_id=row[20],
                    event_args=end_args
                ))

        except sqlite3.Error as e:
            print(f"Error loading memory allocation events from view: {e}")

    def __next__(self):
        """Return the next message."""
        if self._state == "stream_beginning":
            self._state = "packet_beginning"
            return self._create_stream_beginning_message(self._stream)

        elif self._state == "packet_beginning":
            # Create a packet for this stream
            if not hasattr(self, '_packet'):
                self._packet = self._stream.create_packet()
            self._state = "events"
            # Get the timestamp of the first event if available
            first_timestamp = 0
            if self._current_events:
                first_timestamp = self._current_events[0].timestamp
            return self._create_packet_beginning_message(self._packet, default_clock_snapshot=first_timestamp)

        elif self._state == "events":
            if self._event_index < len(self._current_events):
                event_data = self._current_events[self._event_index]
                self._event_index += 1

                # Determine event class based on event category and name
                event_class_name = self._get_event_class_name_by_category(event_data)
                event_class = self._event_classes.get(event_class_name)

                if event_class is None:
                    # Fall back to generic event if specific class not found
                    # Try with start/end suffixes first
                    if event_class_name.endswith('_start'):
                        event_class_name = "generic_event_start"
                    elif event_class_name.endswith('_end'):
                        event_class_name = "generic_event_end"
                    else:
                        event_class_name = "generic_event"
                    event_class = self._event_classes.get(event_class_name)

                # Create an event message
                msg = self._create_event_message(
                    event_class,
                    self._packet,
                    default_clock_snapshot=event_data.timestamp
                )

                # Set event fields based on event data
                self._set_event_fields(msg, event_data, event_class_name)

                return msg

            else:
                # No more events, end the packet
                self._state = "packet_end"
                # Get the timestamp of the last event for packet end
                last_timestamp = 0
                if self._current_events:
                    last_timestamp = self._current_events[-1].timestamp
                return self._create_packet_end_message(self._packet, default_clock_snapshot=last_timestamp)

        elif self._state == "packet_end":
            # End the stream if in packet end state
            self._state = "stream_end"
            return self._create_stream_end_message(self._stream)

        raise StopIteration

    def _get_event_class_name_by_category(self, event_data: RocmEventData) -> str:
        """Get the event class name based on event category and name."""
        # Determine if this is a start or end event based on event_type
        suffix = ''
        if hasattr(event_data, 'event_args') and event_data.event_args:
            event_type = event_data.event_args.get('event_type', '')
            if event_type == 'region_start':
                suffix = '_start'
            elif event_type == 'region_end':
                suffix = '_end'
            elif event_type.endswith('_start'):
                suffix = '_start'
            elif event_type.endswith('_end'):
                suffix = '_end'

        # Also check event name for start/end patterns if event_type doesn't indicate
        if not suffix and hasattr(event_data, 'name') and event_data.name:
            if event_data.name.endswith('_start'):
                suffix = '_start'
            elif event_data.name.endswith('_end'):
                suffix = '_end'

        if hasattr(event_data, 'category') and event_data.category:
            category = event_data.category.lower()

            # Map categories to specific event types
            if category == 'hip_runtime_api_ext' or category == 'hip_runtime_api':
                return f'hip_runtime_region_event{suffix}'
            elif category == 'hip_compiler_api_ext' or category == 'hip_compiler_api':
                return f'hip_compiler_region_event{suffix}'
            elif category == 'hsa_core_api':
                return f'hsa_core_region_event{suffix}'
            elif category == 'hsa_amd_ext_api':
                return f'hsa_amd_ext_region_event{suffix}'
            elif category == 'marker_core_api':
                return f'marker_core_region_event{suffix}'
            elif category == 'kernel_dispatch':
                return f'kernel_dispatch_event{suffix}'
            elif category == 'memory_copy':
                return f'memory_copy_event{suffix}'
            elif category == 'memory_allocation':
                return f'memory_allocation_event{suffix}'
            elif category == 'counter_collection':
                return f'counter_collection_event{suffix}'
            elif category == 'rocdecode_api_ext' or category == 'rocdecode_api':
                return f'rocdecode_region_event{suffix}'
            elif category == 'rocjpeg_api':
                return f'rocjpeg_region_event{suffix}'
            elif category == 'scratch_memory':
                return f'scratch_memory_region_event{suffix}'
            elif category == 'rccl_api':
                return f'rccl_region_event{suffix}'
            elif category == 'ompt':
                return f'ompt_region_event{suffix}'
            elif category == 'kfd_page_migrate':
                return f'kfd_page_migration_region_event{suffix}'
            elif category == 'kfd_page_fault':
                return f'kfd_page_fault_region_event{suffix}'
            elif "region" in event_data.name:
                return f'region_event{suffix}'

        # Fall back to original logic
        return self._get_event_class_name(event_data.name)

    def _get_event_class_name(self, event_name: str) -> str:
        """Get the event class name based on event name (fallback method)."""
        # Determine if this is a start or end event
        suffix = ''
        if event_name.endswith('_start'):
            suffix = '_start'
        elif event_name.endswith('_end'):
            suffix = '_end'

        # Simple mapping based on event name patterns
        if 'kernel_dispatch' in event_name.lower():
            return f'kernel_dispatch_event{suffix}'
        elif 'kernel' in event_name.lower():
            return f'kernel_dispatch_event{suffix}'
        elif 'memory_allocation' in event_name.lower():
            return f'memory_allocation_event{suffix}'
        elif 'memory_copy' in event_name.lower():
            return f'memory_copy_event{suffix}'
        elif 'memory' in event_name.lower():
            return f'memory_copy_event{suffix}'
        elif 'sample' in event_name.lower():
            return f'sample_event{suffix}'
        elif 'region' in event_name.lower():
            return f'region_event{suffix}'
        else:
            # Default fallback
            return f'generic_event{suffix}'

    def _set_event_fields(self, msg, event_data, event_class_name):
        """Set event fields based on event data and event class type."""
        payload = msg.event.payload_field

        # Set common fields that all events have
        if hasattr(event_data, 'name') and event_data.name is not None:
            if 'name' in payload:
                payload['name'] = event_data.name

        if hasattr(event_data, 'category') and event_data.category is not None and 'category' in payload:
            payload['category'] = event_data.category

        if hasattr(event_data, 'duration') and event_data.duration is not None and 'duration' in payload:
            payload['duration'] = event_data.duration

        # Set event-specific fields based on event class name
        base_event_class = event_class_name.replace('_start', '').replace('_end', '')

        if base_event_class == "region_event" or base_event_class.endswith("_region_event"):
            # Region events have region_name, duration, and other region-specific fields
            pass  # Common fields already set above

        elif base_event_class == "kernel_dispatch_event":
            # Kernel dispatch events have all the kernel fields - handled via event_args below
            pass

        elif base_event_class == "memory_copy_event":
            # Memory copy events have memory-specific fields - handled via event_args below
            pass

        elif base_event_class == "memory_allocation_event":
            # Memory allocation events have allocation-specific fields - handled via event_args below
            pass

        elif base_event_class == "counter_collection_event":
            # Counter collection events have counter-specific fields
            if hasattr(event_data, 'counter_id') and event_data.counter_id is not None and 'counter_id' in payload:
                payload['counter_id'] = event_data.counter_id
            if hasattr(event_data, 'value') and event_data.value is not None and 'value' in payload:
                payload['value'] = event_data.value
            if hasattr(event_data, 'counter_symbol') and event_data.counter_symbol is not None and 'counter_symbol' in payload:
                payload['counter_symbol'] = event_data.counter_symbol
            if hasattr(event_data, 'description') and event_data.description is not None and 'description' in payload:
                payload['description'] = event_data.description

        # For all event types, try to set any matching fields from event_args
        if hasattr(event_data, 'event_args') and event_data.event_args:
            for key, value in event_data.event_args.items():
                # Skip event_type since it's now encoded in the class name
                if key == 'event_type':
                    continue
                if key in payload and value is not None:
                    payload[key] = value

    def _get_event_class_name(self, event_name: str) -> str:
        """Get the event class name based on event name (fallback method)."""
        # Simple mapping based on event name patterns
        if 'kernel_dispatch' in event_name.lower():
            return 'kernel_dispatch_event'
        elif 'kernel' in event_name.lower():
            return 'kernel_dispatch_event'
        elif 'memory_allocation' in event_name.lower():
            return 'memory_allocation_event'
        elif 'memory_copy' in event_name.lower():
            return 'memory_copy_event'
        elif 'memory' in event_name.lower():
            return 'memory_copy_event'
        elif 'sample' in event_name.lower():
            return 'sample_event'
        elif 'region' in event_name.lower():
            return 'region_event'
        else:
            # Default fallback
            return 'generic_event'

def __del__(self):
        """Cleanup database connection."""
        if hasattr(self, '_conn'):
            self._conn.close()


@bt2.plugin_component_class
class RocmSource(bt2._UserSourceComponent, message_iterator_class=RocmSourceIterator):
    """Source component for reading ROCm profiler SQLite3 databases."""

    def __init__(self, config, params, obj):
        """Initialize the source component."""
        # Get database path from parameters
        self._db_path = str(params.get('db-path', '24228_results.db'))

        if not self._db_path:
            raise ValueError("Database path parameter 'db-path' is required")

        if not os.path.exists(self._db_path):
            raise FileNotFoundError(f"Database file not found: {self._db_path}")

        # Create trace class
        self._trace_class = super()._create_trace_class()

        # Create clock class
        self._clock_class = self._create_clock_class(
            name="rocm_clock",
            description="ROCm profiler clock",
            frequency=1_000_000_000  # Nanoseconds
        )

        # Create stream class with packet support
        self._stream_class = self._trace_class.create_stream_class(
            name="rocm_stream",
            default_clock_class=self._clock_class,
            supports_packets=True,
            packets_have_beginning_default_clock_snapshot=True,
            packets_have_end_default_clock_snapshot=True
        )

        # Create event classes
        self._event_classes = self._create_event_classes()

        # Create output port
        self._add_output_port("out", {
            'db_path': self._db_path,
            'trace_class': self._trace_class,
            'stream_class': self._stream_class,
            'event_classes': self._event_classes,
            'clock_class': self._clock_class
        })

    def _create_clock_class(self, name: str, description: str, frequency: int):
        """Create a clock class for ROCm events."""
        clock_class = super()._create_clock_class(
            name=name,
            description=description,
            frequency=frequency
        )
        return clock_class

    def _create_event_classes(self) -> Dict[str, Any]:
        """Create event classes for different ROCm event types."""
        event_classes = {}

        # Helper function to create both start and end event classes
        def create_event_class_pair(base_name: str, field_class_factory):
            """Create both start and end event classes for a given base event type."""
            # Create start event class
            start_name = f"{base_name}_start"
            start_field_class = field_class_factory()
            start_event_class = self._stream_class.create_event_class(
                name=start_name,
                payload_field_class=start_field_class
            )
            event_classes[start_name] = start_event_class

            # Create end event class
            end_name = f"{base_name}_end"
            end_field_class = field_class_factory()
            end_event_class = self._stream_class.create_event_class(
                name=end_name,
                payload_field_class=end_field_class
            )
            event_classes[end_name] = end_event_class

            # Also create the base event class for compatibility
            base_field_class = field_class_factory()
            base_event_class = self._stream_class.create_event_class(
                name=base_name,
                payload_field_class=base_field_class
            )
            event_classes[base_name] = base_event_class

        # Create field class factory for region events
        def create_region_field_class():
            fc = self._trace_class.create_structure_field_class()
            fc.append_member("region_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("guid", self._trace_class.create_string_field_class())
            fc.append_member("name", self._trace_class.create_string_field_class())
            fc.append_member("category", self._trace_class.create_string_field_class())
            fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("event_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("parent_stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("extdata", self._trace_class.create_string_field_class())
            fc.append_member("call_stack", self._trace_class.create_string_field_class())
            fc.append_member("line_info", self._trace_class.create_string_field_class())
            return fc

        # Create field class factory for kernel dispatch events
        def create_kernel_dispatch_field_class():
            fc = self._trace_class.create_structure_field_class()
            fc.append_member("kernel_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("guid", self._trace_class.create_string_field_class())
            fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("category", self._trace_class.create_string_field_class())
            fc.append_member("region", self._trace_class.create_string_field_class())
            fc.append_member("name", self._trace_class.create_string_field_class())
            fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_abs_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_log_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_type_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_type", self._trace_class.create_string_field_class())
            fc.append_member("code_object_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("kernel_symbol_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("dispatch_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("stream_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("queue_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("queue_name", self._trace_class.create_string_field_class())
            fc.append_member("stream_name", self._trace_class.create_string_field_class())
            fc.append_member("grid_size_x", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("grid_size_y", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("grid_size_z", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("workgroup_size_x", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("workgroup_size_y", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("workgroup_size_z", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("lds_size", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("scratch_size", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("static_lds_size", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("static_scratch_size", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("parent_stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
            return fc

        # Create field class factory for memory copy events
        def create_memory_copy_field_class():
            fc = self._trace_class.create_structure_field_class()
            fc.append_member("copy_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("guid", self._trace_class.create_string_field_class())
            fc.append_member("category", self._trace_class.create_string_field_class())
            fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("name", self._trace_class.create_string_field_class())
            fc.append_member("region_name", self._trace_class.create_string_field_class())
            fc.append_member("stream_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("queue_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("stream_name", self._trace_class.create_string_field_class())
            fc.append_member("queue_name", self._trace_class.create_string_field_class())
            fc.append_member("size", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("dst_device", self._trace_class.create_string_field_class())
            fc.append_member("dst_agent_abs_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("dst_agent_log_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("dst_agent_type_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("dst_agent_type", self._trace_class.create_string_field_class())
            fc.append_member("dst_address", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("src_device", self._trace_class.create_string_field_class())
            fc.append_member("src_agent_abs_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("src_agent_log_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("src_agent_type_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("src_agent_type", self._trace_class.create_string_field_class())
            fc.append_member("src_address", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("parent_stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
            return fc

        # Create field class factory for memory allocation events
        def create_memory_allocation_field_class():
            fc = self._trace_class.create_structure_field_class()
            fc.append_member("allocation_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("guid", self._trace_class.create_string_field_class())
            fc.append_member("category", self._trace_class.create_string_field_class())
            fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("allocation_type", self._trace_class.create_string_field_class())
            fc.append_member("level", self._trace_class.create_string_field_class())
            fc.append_member("agent_name", self._trace_class.create_string_field_class())
            fc.append_member("agent_abs_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_log_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_type_index", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("agent_type", self._trace_class.create_string_field_class())
            fc.append_member("address", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("size", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("queue_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("queue_name", self._trace_class.create_string_field_class())
            fc.append_member("stream_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("stream_name", self._trace_class.create_string_field_class())
            fc.append_member("stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("parent_stack_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
            fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
            return fc

        # Create event class pairs for all event types
        create_event_class_pair("region_event", create_region_field_class)
        create_event_class_pair("kernel_dispatch_event", create_kernel_dispatch_field_class)
        create_event_class_pair("memory_copy_event", create_memory_copy_field_class)
        create_event_class_pair("memory_allocation_event", create_memory_allocation_field_class)

        # Create event class pairs for all region event types
        create_event_class_pair("hip_runtime_region_event", create_region_field_class)
        create_event_class_pair("hip_compiler_region_event", create_region_field_class)
        create_event_class_pair("hsa_core_region_event", create_region_field_class)
        create_event_class_pair("hsa_amd_ext_region_event", create_region_field_class)
        create_event_class_pair("marker_core_region_event", create_region_field_class)
        create_event_class_pair("kernel_dispatch_region_event", create_region_field_class)
        create_event_class_pair("memory_copy_region_event", create_region_field_class)
        create_event_class_pair("rocdecode_region_event", create_region_field_class)
        create_event_class_pair("rocjpeg_region_event", create_region_field_class)
        create_event_class_pair("rccl_region_event", create_region_field_class)
        create_event_class_pair("scratch_memory_region_event", create_region_field_class)
        create_event_class_pair("ompt_region_event", create_region_field_class)
        create_event_class_pair("kfd_page_migration_region_event", create_region_field_class)
        create_event_class_pair("kfd_page_fault_region_event", create_region_field_class)

        # Sample event class (single event, no start/end)
        sample_payload_fc = self._trace_class.create_structure_field_class()
        sample_payload_fc.append_member("sample_id", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("guid", self._trace_class.create_string_field_class())
        sample_payload_fc.append_member("category", self._trace_class.create_string_field_class())
        sample_payload_fc.append_member("name", self._trace_class.create_string_field_class())
        sample_payload_fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("event_id", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("stack_id", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("parent_stack_id", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
        sample_payload_fc.append_member("extdata", self._trace_class.create_string_field_class())
        sample_payload_fc.append_member("call_stack", self._trace_class.create_string_field_class())
        sample_payload_fc.append_member("line_info", self._trace_class.create_string_field_class())
        sample_event_class = self._stream_class.create_event_class(
            name="sample_event",
            payload_field_class=sample_payload_fc
        )
        event_classes["sample_event"] = sample_event_class

        # Counter Collection event class (single event, no start/end)
        counter_collection_payload_fc = self._trace_class.create_structure_field_class()
        counter_collection_payload_fc.append_member("id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("guid", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("dispatch_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("kernel_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("event_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("correlation_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("stack_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("parent_stack_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("pid", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("tid", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("agent_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("agent_abs_index", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("agent_log_index", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("agent_type_index", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("agent_type", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("queue_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("grid_size_x", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("grid_size_y", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("grid_size_z", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("name", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("kernel_region", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("workgroup_size_x", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("workgroup_size_y", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("workgroup_size_z", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("lds_block_size", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("scratch_size", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("vgpr_count", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("accum_vgpr_count", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("sgpr_count", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("counter_name", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("counter_symbol", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("component", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("description", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("block", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("expression", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("value_type", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("counter_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("value", self._trace_class.create_double_precision_real_field_class())
        counter_collection_payload_fc.append_member("start", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("end", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("is_constant", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("is_derived", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("category", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("nid", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_payload_fc.append_member("extdata", self._trace_class.create_string_field_class())
        counter_collection_payload_fc.append_member("code_object_id", self._trace_class.create_signed_integer_field_class(64))
        counter_collection_event_class = self._stream_class.create_event_class(
            name="counter_collection_event",
            payload_field_class=counter_collection_payload_fc
        )
        event_classes["counter_collection_event"] = counter_collection_event_class

        # Generic event class (with start/end variants)
        def create_generic_field_class():
            fc = self._trace_class.create_structure_field_class()
            fc.append_member("name", self._trace_class.create_string_field_class())
            fc.append_member("category", self._trace_class.create_string_field_class())
            fc.append_member("duration", self._trace_class.create_signed_integer_field_class(64))
            return fc

        create_event_class_pair("generic_event", create_generic_field_class)

        return event_classes

    @staticmethod
    def _user_query(priv_executor, obj, query, params):
        """Handle query requests."""
        if query == "babeltrace.support-info":
            # Support SQLite3 files that contain ROCm profiler tables
            input_value = params.get('input')
            if not input_value:
                return {'weight': 0.0}

            # Check if it's a file path
            if not isinstance(input_value, str):
                return {'weight': 0.0}

            # Check if file exists and is SQLite
            if not os.path.exists(input_value):
                return {'weight': 0.0}

            try:
                # Quick check if it's a SQLite database with ROCm tables
                conn = sqlite3.connect(input_value)
                cursor = conn.cursor()

                # Check for ROCm-specific tables
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'rocpd_%'")
                rocm_tables = cursor.fetchall()

                conn.close()

                if rocm_tables:
                    return {'weight': 1.0}  # Perfect match
                else:
                    return {'weight': 0.0}  # Not a ROCm database

            except Exception:
                return {'weight': 0.0}

        elif query == "babeltrace.mip-version":
            # Declare MIP version support
            return 0  # Support MIP version 0



        return None

    @classmethod
    def _user_get_supported_mip_versions(cls, params, obj, log_level):
        """Return the supported MIP versions."""
        return [0]
